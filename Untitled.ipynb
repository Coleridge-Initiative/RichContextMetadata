{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'metadata_funs' from '/Users/sophierand/RichContextMetadata/metadata_funs.py'>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import metadata_funs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import metadata_funs\n",
    "import getpass\n",
    "import pandas\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import dateutil.parser as dparser\n",
    "import pandas as pd\n",
    "import metadata_funs\n",
    "import importlib\n",
    "importlib.reload(metadata_funs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_thing():\n",
    "    a_list = []\n",
    "    try:\n",
    "        for i in range(10):\n",
    "            print(i)\n",
    "            time.sleep( 1 )\n",
    "            a_list.append('a thingie {}'.format(i))\n",
    "        return a_list\n",
    "    except KeyboardInterrupt:\n",
    "        return a_list\n",
    "#     return a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gen_ds_names(dataset_names):\n",
    "    \"\"\"\n",
    "    combine dataset name with dataset alias (if it exists)\n",
    "    and output as dict with dataset_id (for input to return_string_search_dyads)\n",
    "    \"\"\"\n",
    "    ds_names = []\n",
    "    for d in dataset_names:\n",
    "        name = metadata_funs.scrub_unicode(d['title'])\n",
    "        dataset_id = d['dataset_id']\n",
    "        try:\n",
    "            alias = metadata_funs.scrub_unicode(d['alias'])\n",
    "#             ds_dict = {'dataset_name':list((name,alias)),'dataset_id':dataset_id}\n",
    "            ds_dict = {'dataset_name':list(set(list((name,alias)))),'dataset_id':dataset_id}\n",
    "        except:\n",
    "            ds_dict = {'dataset_name':[name],'dataset_id':dataset_id}        \n",
    "        ds_names.append(ds_dict)\n",
    "    return ds_names\n",
    "\n",
    "\n",
    "new_list = []\n",
    "def filter_ids():\n",
    "    search_path = '/Users/sophierand/RichContextMetadata/metadata/'\n",
    "    pub_paths = [search_path+f for f in os.listdir(search_path) if f.endswith(\"stringsearch_pubs.json\")]\n",
    "    for p in pub_paths:\n",
    "        file_date = dparser.parse(time.ctime(os.path.getctime(p)),fuzzy=True).date()\n",
    "        with open(p) as json_file:\n",
    "            ss_json = json.load(json_file)\n",
    "        a = [{'ds_name':s['related_dataset_name'],'ds_id':s['related_dataset']\n",
    "      ,'linkage_source':s['linkage_source'],'file_run':file_date\n",
    "    ,'time_since_run':abs((file_date - datetime.datetime.now().date()).days)} for s in ss_json]\n",
    "        b = [dict(t) for t in {tuple(d.items()) for d in a}]\n",
    "        new_list.append(b)\n",
    "    ss_pub_list_flat = metadata_funs.flatten(new_list)\n",
    "    b_exclude = list(set([d['ds_id'] for d in ss_pub_list_flat if d['time_since_run'] <= 30]))\n",
    "    return b_exclude\n",
    "\n",
    "    \n",
    "\n",
    "def return_string_search_dyads(dataset_string, api_client):\n",
    "    \"\"\"\n",
    "    intake a dataset name\n",
    "    , identify papers with that term in the full text\n",
    "    , and return publication metadata\n",
    "    \"\"\"\n",
    "    api_return = metadata_funs.run_exact_string_search(string = dataset_string, api_client = api_client)\n",
    "    pub_metadata = []\n",
    "    for i in api_return['publications']:\n",
    "        time.sleep( 6 )\n",
    "        pub_id = i['id']\n",
    "        id_metadata = metadata_funs.run_pub_id_search(dimensions_id = pub_id, api_client = api_client)\n",
    "        id_metadata.update({'dimensions_id':pub_id,'related_dataset_name':dataset_string})\n",
    "        pub_metadata.append(id_metadata)\n",
    "    return pub_metadata\n",
    "\n",
    "\n",
    "    \n",
    "def gen_ss_dyad(dataset_name_dict,api_client):\n",
    "    \"\"\"\n",
    "    intake a dataset dictionary that has a dataset_id and a list of names (name+alias)\n",
    "    , and each is run through the string_search_dyads function to return publication metadata\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_names_list = dataset_name_dict['dataset_name']\n",
    "    dataset_id = dataset_name_dict['dataset_id']\n",
    "    store_dyads = []\n",
    "    for ds in dataset_names_list:\n",
    "        pub_dataset_dyads  = return_string_search_dyads(dataset_string = ds, api_client = api_client)\n",
    "        store_dyads.append(pub_dataset_dyads)\n",
    "    store_dyads_flat = metadata_funs.flatten(store_dyads)\n",
    "    for s in store_dyads_flat:\n",
    "        s.update({'related_dataset':dataset_id,'linkage_source':'dataset_stringsearch'})\n",
    "    return store_dyads_flat\n",
    "\n",
    "\n",
    "def gen_dyad_list(ds_names):\n",
    "    \"\"\"\n",
    "    intake a list of dataset dictionaries\n",
    "    , where each dict has a dataset_id and a list of names (name+alias)\n",
    "    , and run through gen_ss_dyad\n",
    "    \"\"\"\n",
    "    big_list = []\n",
    "    try:\n",
    "        for d in ds_names:\n",
    "#             print('looking for ',d, ' now')\n",
    "            a = 'i would do a string search with {}'.format(d)\n",
    "#             a = gen_ss_dyad(dataset_name_dict = d,api_client = api_client)\n",
    "            big_list.append(a)\n",
    "            time.sleep(1)\n",
    "        return big_list\n",
    "    except KeyboardInterrupt:\n",
    "        return big_list\n",
    "#     return big_list\n",
    "\n",
    "# def gen_dyad_list(ds_names):\n",
    "#     \"\"\"\n",
    "#     intake a list of dataset dictionaries\n",
    "#     , where each dict has a dataset_id and a list of names (name+alias)\n",
    "#     , and run through gen_ss_dyad\n",
    "#     \"\"\"\n",
    "#     big_list = []\n",
    "#     for d in ds_names:\n",
    "#         print('looking for ',d, ' now')\n",
    "#         a = gen_ss_dyad(dataset_name_dict = d,api_client = api_client)\n",
    "#         big_list.append(a)\n",
    "#     return big_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter your dimensions api username\n",
      "sr2661@nyu.edu\n",
      "enter your dimensions api password\n",
      "········\n",
      "API credentials have been set\n"
     ]
    }
   ],
   "source": [
    "api_client = metadata_funs.create_api_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = metadata_funs.read_datasets()\n",
    "ds_names = gen_ds_names(dataset_names)\n",
    "exclude_ids = filter_ids()\n",
    "# ds_names_lim = [d for d  in ds_names if d['dataset_id'] in ['dataset-b48654a3feb4deaaa272','dataset-53fcd9fbd727f01baad3']]\n",
    "ds_names_lim = ds_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_list = gen_dyad_list(ds_names = ds_names_lim)\n",
    "# d = 'External Position of Banks'\n",
    "# a = gen_ss_dyad(dataset_name_dict = ds_names_lim[0],api_client = api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i would do a string search with {'dataset_name': ['External Position of Banks', 'AUSTA'], 'dataset_id': 'dataset-b48654a3feb4deaaa272'}\",\n",
       " \"i would do a string search with {'dataset_name': ['VJKRE', 'Quarterly borrower statistics'], 'dataset_id': 'dataset-e60ec495ae9942bcfabd'}\",\n",
       " \"i would do a string search with {'dataset_name': ['USTAN', 'Corporate balance sheets'], 'dataset_id': 'dataset-8a1ecadc065cd96080e6'}\",\n",
       " \"i would do a string search with {'dataset_name': ['Securities Holdings Statistics - Base', 'SHS-BASE'], 'dataset_id': 'dataset-7f96cddfcd84cf53dc01'}\",\n",
       " \"i would do a string search with {'dataset_name': ['PHF', 'Panel on Household Finances'], 'dataset_id': 'dataset-53fcd9fbd727f01baad3'}\",\n",
       " \"i would do a string search with {'dataset_name': ['Investment Funds Statistics - Base', 'IFS-BASE'], 'dataset_id': 'dataset-0710bb97f8650281c188'}\",\n",
       " \"i would do a string search with {'dataset_name': ['MFI Interest Rate Statistics', 'ZISTA'], 'dataset_id': 'dataset-65a4641708c72cf803d6'}\",\n",
       " \"i would do a string search with {'dataset_name': ['OECD Survey on Adult Financial Literacy in Germany'], 'dataset_id': 'dataset-36a6da383deb2261e284'}\",\n",
       " \"i would do a string search with {'dataset_name': ['BAKIS', 'BAKIS-M'], 'dataset_id': 'dataset-38916e1949eaf3be8941'}\",\n",
       " \"i would do a string search with {'dataset_name': ['BISTA', 'Monthly balance sheet statistics'], 'dataset_id': 'dataset-24cedd45ae05ab3ded81'}\",\n",
       " 'i would do a string search with {\\'dataset_name\\': [\\'GUV\\', \"Statistics of the banks\\' profit and loss accounts\"], \\'dataset_id\\': \\'dataset-0d8a1e97eb40d9f44975\\'}',\n",
       " \"i would do a string search with {'dataset_name': ['MIDI', 'Microdatabase Direct Investment'], 'dataset_id': 'dataset-e1d4f401a412761b3ed9'}\",\n",
       " \"i would do a string search with {'dataset_name': ['Statistics on International Trade in Services', 'SITS'], 'dataset_id': 'dataset-576efc10fc453835f4b5'}\",\n",
       " \"i would do a string search with {'dataset_name': ['ZentK', 'Zentralkartei Banken'], 'dataset_id': 'dataset-f744543fdae124bae674'}\",\n",
       " \"i would do a string search with {'dataset_name': ['BLS', 'Bank Lending Survey'], 'dataset_id': 'dataset-86320022f75a9bac3a6b'}\",\n",
       " \"i would do a string search with {'dataset_name': ['MIMIK', 'MiMiK'], 'dataset_id': 'dataset-c2001ca53104f07ee73f'}\",\n",
       " \"i would do a string search with {'dataset_name': ['Payment behaviour in Germany', 'PaymentSurvey'], 'dataset_id': 'dataset-800f0a3295b76b2056a1'}\",\n",
       " \"i would do a string search with {'dataset_name': ['Centralised Securities Database', 'CSDB'], 'dataset_id': 'dataset-b0dbbe35652387cdd150'}\",\n",
       " \"i would do a string search with {'dataset_name': ['TARGET2'], 'dataset_id': 'dataset-90fe7dbb02b4f7d4ee4f'}\",\n",
       " \"i would do a string search with {'dataset_name': ['Annual Distress Database of the Deutsche Bundesbank', 'SRP'], 'dataset_id': 'dataset-06bc9a7136827dcf3c70'}\"]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    big_list = gen_dyad_list(ds_names = ds_names_lim)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('you interuppted me but i finished and i made thtis',big_list)\n",
    "#     sys.exit()tsys.e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
