{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating `publications.json` partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a template notebook for generating metadata on publications - most importantly, the linkage between the publication and dataset (datasets are enumerated in `datasets.json`)\n",
    "\n",
    "Process goes as follows:\n",
    "1. Import CSV with publication-dataset linkages. Your csv should have at the minimum, fields (spelled like the below):\n",
    "    * `dataset` to hold the dataset_ids, and \n",
    "    * `title` for the publication title. \n",
    "\n",
    "Update the csv with these field names to ensure this code will run.  We read in, dedupe and format the title\n",
    "2. Match to `datasets.json` -- alert if given dataset doesn't exist yet\n",
    "3. Generate list of dicts with publication metadata\n",
    "4. Write to a publications.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import CSV containing publication-dataset linkages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `linkages_path` to the location of the csv containg dataset-publication linkages and read in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'foodaps_usda_linkages.csv'\n",
    "rcm_subfolder = '20190619_usda_foodaps'\n",
    "\n",
    "linkages_path =  os.path.join('/Users/andrewnorris/RichContextMetadata/metadata',rcm_subfolder,file_name)\n",
    "# linkages_path =  os.path.join(os.getcwd(),'SNAP_DATA_DIMENSIONS_SEARCH_DEMO.csv')\n",
    "linkages_csv = pd.read_csv(linkages_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/andrewnorris/RichContextMetadata/metadata/20190619_usda_foodaps/foodaps_usda_linkages.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkages_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format/clean linkage data - apply `scrub_unicode` to `title` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_unicode (text):\n",
    "    \"\"\"\n",
    "    try to handle the unicode edge cases encountered in source text,\n",
    "    as best as possible\n",
    "    \"\"\"\n",
    "    x = \" \".join(map(lambda s: s.strip(), text.split(\"\\n\"))).strip()\n",
    "\n",
    "    x = x.replace('“', '\"').replace('”', '\"')\n",
    "    x = x.replace(\"‘\", \"'\").replace(\"’\", \"'\").replace(\"`\", \"'\")\n",
    "    x = x.replace(\"`` \", '\"').replace(\"''\", '\"')\n",
    "    x = x.replace('…', '...').replace(\"\\\\u2026\", \"...\")\n",
    "    x = x.replace(\"\\\\u00ae\", \"\").replace(\"\\\\u2122\", \"\")\n",
    "    x = x.replace(\"\\\\u00a0\", \" \").replace(\"\\\\u2022\", \"*\").replace(\"\\\\u00b7\", \"*\")\n",
    "    x = x.replace(\"\\\\u2018\", \"'\").replace(\"\\\\u2019\", \"'\").replace(\"\\\\u201a\", \"'\")\n",
    "    x = x.replace(\"\\\\u201c\", '\"').replace(\"\\\\u201d\", '\"')\n",
    "\n",
    "    x = x.replace(\"\\\\u20ac\", \"€\")\n",
    "    x = x.replace(\"\\\\u2212\", \" - \") # minus sign\n",
    "\n",
    "    x = x.replace(\"\\\\u00e9\", \"é\")\n",
    "    x = x.replace(\"\\\\u017c\", \"ż\").replace(\"\\\\u015b\", \"ś\").replace(\"\\\\u0142\", \"ł\")    \n",
    "    x = x.replace(\"\\\\u0105\", \"ą\").replace(\"\\\\u0119\", \"ę\").replace(\"\\\\u017a\", \"ź\").replace(\"\\\\u00f3\", \"ó\")\n",
    "\n",
    "    x = x.replace(\"\\\\u2014\", \" - \").replace('–', '-').replace('—', ' - ')\n",
    "    x = x.replace(\"\\\\u2013\", \" - \").replace(\"\\\\u00ad\", \" - \")\n",
    "\n",
    "    x = str(unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"utf-8\"))\n",
    "\n",
    "    # some content returns text in bytes rather than as a str ?\n",
    "    try:\n",
    "        assert type(x).__name__ == \"str\"\n",
    "    except AssertionError:\n",
    "        print(\"not a string?\", type(x), x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrub titles of problematic characters, drop nulls and dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dataset-025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States Department of Agriculture, Econo...</td>\n",
       "      <td>WIC Households' Food Purchases Using WIC Benef...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ers.usda.gov/webdocs/publications/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>dataset-025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States Department of Agriculture, Econo...</td>\n",
       "      <td>USDA's National Household Food Acquisition and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ageconsearch.umn.edu/record/276252/fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>dataset-025</td>\n",
       "      <td>10.1016/j.foodpol.2018.03.007</td>\n",
       "      <td>Food Policy</td>\n",
       "      <td>Overview: Exploring ways to encourage healthie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.elsevier.com/content/article/PII:S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dataset-025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States Department of Agriculture, Econo...</td>\n",
       "      <td>Supermarkets, Schools, and Social Gatherings: ...</td>\n",
       "      <td>https://www.ers.usda.gov/amber-waves/2018/janu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dataset-025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States Department of Agriculture, Econo...</td>\n",
       "      <td>Nutritional Quality of Foods Acquired by Ameri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.ers.usda.gov/webdocs/publications/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset                            doi  \\\n",
       "0  dataset-025                            NaN   \n",
       "1  dataset-025                            NaN   \n",
       "2  dataset-025  10.1016/j.foodpol.2018.03.007   \n",
       "3  dataset-025                            NaN   \n",
       "4  dataset-025                            NaN   \n",
       "\n",
       "                                             journal  \\\n",
       "0  United States Department of Agriculture, Econo...   \n",
       "1  United States Department of Agriculture, Econo...   \n",
       "2                                        Food Policy   \n",
       "3  United States Department of Agriculture, Econo...   \n",
       "4  United States Department of Agriculture, Econo...   \n",
       "\n",
       "                                               title  \\\n",
       "0  WIC Households' Food Purchases Using WIC Benef...   \n",
       "1  USDA's National Household Food Acquisition and...   \n",
       "2  Overview: Exploring ways to encourage healthie...   \n",
       "3  Supermarkets, Schools, and Social Gatherings: ...   \n",
       "4  Nutritional Quality of Foods Acquired by Ameri...   \n",
       "\n",
       "                                                 url  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  https://www.ers.usda.gov/amber-waves/2018/janu...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                 pdf  \n",
       "0  https://www.ers.usda.gov/webdocs/publications/...  \n",
       "1  https://ageconsearch.umn.edu/record/276252/fil...  \n",
       "2  https://api.elsevier.com/content/article/PII:S...  \n",
       "3                                                NaN  \n",
       "4  https://www.ers.usda.gov/webdocs/publications/...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkages_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkages_csv['title'] = linkages_csv['title'].apply(scrub_unicode)\n",
    "linkages_csv = linkages_csv.loc[pd.notnull(linkages_csv.dataset)].drop_duplicates()\n",
    "linkages_csv = linkages_csv.loc[pd.notnull(linkages_csv.title)].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_metadata_fields = ['title']\n",
    "original_metadata_cols = list(set(linkages_csv.columns.values.tolist()) - set(pub_metadata_fields)-set(['dataset']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate list of dicts of metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in `datasets.json`. Update `datasets_path` to your local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = '/Users/andrewnorris/RCDatasets/datasets.json'\n",
    "\n",
    "with open(datasets_path) as json_file:\n",
    "    datasets = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of dictionaries of publication metadata. `format_metadata` iterrates through `linkages_csv` dataframe, splits the `dataset` field (for when multiple datasets are listed); throws an error if the dataset doesn't exist and needs to be added to `datasets.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pub_dict(linkages_dataframe,datasets):\n",
    "    pub_dict_list = []\n",
    "    for i, r in linkages_dataframe.iterrows():\n",
    "        r['title'] = scrub_unicode(r['title'])\n",
    "        ds_id_list = [f for f in [d.strip() for d in r['dataset'].split(\",\")] if f not in [\"\",\" \"]]\n",
    "        for ds in ds_id_list:\n",
    "            check_ds = [b for b in datasets if b['id'] == ds]\n",
    "            if len(check_ds) == 0:\n",
    "                print('dataset {} isnt listed in datasets.json. Please add to file'.format(ds))\n",
    "        required_metadata = r[pub_metadata_fields].to_dict()\n",
    "        required_metadata.update({'datasets':ds_id_list})\n",
    "        pub_dict = required_metadata\n",
    "        if len(original_metadata_cols) > 0:\n",
    "            original_metadata = r[original_metadata_cols].to_dict()\n",
    "            original_metadata.update({'date_added':datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n",
    "            pub_dict.update({'original':original_metadata})\n",
    "        pub_dict_list.append(pub_dict)\n",
    "    return pub_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate publication metadata and export to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_list = create_pub_dict(linkages_csv,datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update `pub_path` to be: \n",
    "`<name_of_subfolder>_publications.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_pub_path = os.path.join('/Users/andrewnorris/RCPublications/partitions/',rcm_subfolder+'_publications.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_pub_path, 'w') as outfile:\n",
    "    json.dump(linkage_list, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
