{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating `publications.json` partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a template notebook for generating metadata on publications - most importantly, the linkage between the publication and dataset (datasets are enumerated in `datasets.json`)\n",
    "\n",
    "Process goes as follows:\n",
    "1. Import CSV with publication-dataset linkages. Your csv should have at the minimum, fields (spelled like the below):\n",
    "    * `dataset` to hold the dataset_ids, and \n",
    "    * `title` for the publication title. \n",
    "\n",
    "Update the csv with these field names to ensure this code will run.  We read in, dedupe and format the title\n",
    "2. Match to `datasets.json` -- alert if given dataset doesn't exist yet\n",
    "3. Generate list of dicts with publication metadata\n",
    "4. Write to a publications.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import CSV containing publication-dataset linkages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `linkages_path` to the location of the csv containg dataset-publication linkages and read in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'WomensEmploymentStudy_linkages_mynoa.csv'\n",
    "rcm_subfolder = '20191119_WomensEmploymentStudy'\n",
    "parent_folder = '/Users/mynoa/rc_project/RichContextMetadata/metadata'\n",
    "linkages_path =  os.path.join(parent_folder,rcm_subfolder,file_name)\n",
    "# linkages_path =  os.path.join(os.getcwd(),'SNAP_DATA_DIMENSIONS_SEARCH_DEMO.csv')\n",
    "linkages_csv = pd.read_csv(linkages_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format/clean linkage data - apply `scrub_unicode` to `title` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_unicode (text):\n",
    "    \"\"\"\n",
    "    try to handle the unicode edge cases encountered in source text,\n",
    "    as best as possible\n",
    "    \"\"\"\n",
    "    x = \" \".join(map(lambda s: s.strip(), text.split(\"\\n\"))).strip()\n",
    "\n",
    "    x = x.replace('“', '\"').replace('”', '\"')\n",
    "    x = x.replace(\"‘\", \"'\").replace(\"’\", \"'\").replace(\"`\", \"'\")\n",
    "    x = x.replace(\"`` \", '\"').replace(\"''\", '\"')\n",
    "    x = x.replace('…', '...').replace(\"\\\\u2026\", \"...\")\n",
    "    x = x.replace(\"\\\\u00ae\", \"\").replace(\"\\\\u2122\", \"\")\n",
    "    x = x.replace(\"\\\\u00a0\", \" \").replace(\"\\\\u2022\", \"*\").replace(\"\\\\u00b7\", \"*\")\n",
    "    x = x.replace(\"\\\\u2018\", \"'\").replace(\"\\\\u2019\", \"'\").replace(\"\\\\u201a\", \"'\")\n",
    "    x = x.replace(\"\\\\u201c\", '\"').replace(\"\\\\u201d\", '\"')\n",
    "\n",
    "    x = x.replace(\"\\\\u20ac\", \"€\")\n",
    "    x = x.replace(\"\\\\u2212\", \" - \") # minus sign\n",
    "\n",
    "    x = x.replace(\"\\\\u00e9\", \"é\")\n",
    "    x = x.replace(\"\\\\u017c\", \"ż\").replace(\"\\\\u015b\", \"ś\").replace(\"\\\\u0142\", \"ł\")    \n",
    "    x = x.replace(\"\\\\u0105\", \"ą\").replace(\"\\\\u0119\", \"ę\").replace(\"\\\\u017a\", \"ź\").replace(\"\\\\u00f3\", \"ó\")\n",
    "\n",
    "    x = x.replace(\"\\\\u2014\", \" - \").replace('–', '-').replace('—', ' - ')\n",
    "    x = x.replace(\"\\\\u2013\", \" - \").replace(\"\\\\u00ad\", \" - \")\n",
    "\n",
    "    x = str(unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"utf-8\"))\n",
    "\n",
    "    # some content returns text in bytes rather than as a str ?\n",
    "    try:\n",
    "        assert type(x).__name__ == \"str\"\n",
    "    except AssertionError:\n",
    "        print(\"not a string?\", type(x), x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrub titles of problematic characters, drop nulls and dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkages_csv = linkages_csv.loc[pd.notnull(linkages_csv.dataset)].drop_duplicates()\n",
    "linkages_csv = linkages_csv.loc[pd.notnull(linkages_csv.title)].drop_duplicates()\n",
    "linkages_csv['title'] = linkages_csv['title'].apply(scrub_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>search_term</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dataset-147</td>\n",
       "      <td>10.1007/s10896-019-00058-y</td>\n",
       "      <td>Journal of Family Violence</td>\n",
       "      <td>Women's Employment Study</td>\n",
       "      <td>Gender-Based Violence in Senegal: its Catalyst...</td>\n",
       "      <td>https://doi.org/10.1007/s10896-019-00058-y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>dataset-147</td>\n",
       "      <td>10.1080/02673037.2019.1676402</td>\n",
       "      <td>Housing Studies</td>\n",
       "      <td>Women's Employment Study</td>\n",
       "      <td>Beyond households: regional determinants of ho...</td>\n",
       "      <td>https://doi.org/10.1080/02673037.2019.1676402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>dataset-147</td>\n",
       "      <td>10.1080/15564886.2019.1641449</td>\n",
       "      <td>Victims &amp; Offenders</td>\n",
       "      <td>Women's Employment Study</td>\n",
       "      <td>Victimized Twice: A Field Experiment on the Em...</td>\n",
       "      <td>https://doi.org/10.1080/15564886.2019.1641449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dataset-147</td>\n",
       "      <td>10.1080/10511482.2018.1544161</td>\n",
       "      <td>Housing Policy Debate</td>\n",
       "      <td>Women's Employment Study</td>\n",
       "      <td>Why Low-Income Households Become Unstably Hous...</td>\n",
       "      <td>https://doi.org/10.1080/10511482.2018.1544161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dataset-147</td>\n",
       "      <td>10.1080/15555240.2019.1609361</td>\n",
       "      <td>Journal of Workplace Behavioral Health</td>\n",
       "      <td>Women's Employment Study</td>\n",
       "      <td>Workplace interventions for intimate partner v...</td>\n",
       "      <td>https://doi.org/10.1080/15555240.2019.1609361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset                            doi  \\\n",
       "0  dataset-147     10.1007/s10896-019-00058-y   \n",
       "1  dataset-147  10.1080/02673037.2019.1676402   \n",
       "2  dataset-147  10.1080/15564886.2019.1641449   \n",
       "3  dataset-147  10.1080/10511482.2018.1544161   \n",
       "4  dataset-147  10.1080/15555240.2019.1609361   \n",
       "\n",
       "                                  journal               search_term  \\\n",
       "0              Journal of Family Violence  Women's Employment Study   \n",
       "1                         Housing Studies  Women's Employment Study   \n",
       "2                     Victims & Offenders  Women's Employment Study   \n",
       "3                   Housing Policy Debate  Women's Employment Study   \n",
       "4  Journal of Workplace Behavioral Health  Women's Employment Study   \n",
       "\n",
       "                                               title  \\\n",
       "0  Gender-Based Violence in Senegal: its Catalyst...   \n",
       "1  Beyond households: regional determinants of ho...   \n",
       "2  Victimized Twice: A Field Experiment on the Em...   \n",
       "3  Why Low-Income Households Become Unstably Hous...   \n",
       "4  Workplace interventions for intimate partner v...   \n",
       "\n",
       "                                             url  \n",
       "0     https://doi.org/10.1007/s10896-019-00058-y  \n",
       "1  https://doi.org/10.1080/02673037.2019.1676402  \n",
       "2  https://doi.org/10.1080/15564886.2019.1641449  \n",
       "3  https://doi.org/10.1080/10511482.2018.1544161  \n",
       "4  https://doi.org/10.1080/15555240.2019.1609361  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkages_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_metadata_fields = ['title']\n",
    "original_metadata_cols = list(set(linkages_csv.columns.values.tolist()) - set(pub_metadata_fields)-set(['dataset']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate list of dicts of metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in `datasets.json`. Update `datasets_path` to your local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = '/Users/mynoa/rc_project/RCDatasets/datasets.json'\n",
    "\n",
    "with open(datasets_path) as json_file:\n",
    "    datasets = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of dictionaries of publication metadata. `format_metadata` iterrates through `linkages_csv` dataframe, splits the `dataset` field (for when multiple datasets are listed); throws an error if the dataset doesn't exist and needs to be added to `datasets.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pub_dict(linkages_dataframe,datasets):\n",
    "    pub_dict_list = []\n",
    "    for i, r in linkages_dataframe.iterrows():\n",
    "        r['title'] = scrub_unicode(r['title'])\n",
    "        ds_id_list = [f for f in [d.strip() for d in r['dataset'].split(\",\")] if f not in [\"\",\" \"]]\n",
    "        for ds in ds_id_list:\n",
    "            check_ds = [b for b in datasets if b['id'] == ds]\n",
    "            if len(check_ds) == 0:\n",
    "                print('dataset {} isnt listed in datasets.json. Please add to file'.format(ds))\n",
    "        required_metadata = r[pub_metadata_fields].to_dict()\n",
    "        required_metadata.update({'datasets':ds_id_list})\n",
    "        pub_dict = required_metadata\n",
    "        if len(original_metadata_cols) > 0:\n",
    "            original_metadata = r[original_metadata_cols].to_dict()\n",
    "            original_metadata.update({'date_added':datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n",
    "            pub_dict.update({'original':original_metadata})\n",
    "        pub_dict_list.append(pub_dict)\n",
    "    return pub_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate publication metadata and export to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_list = create_pub_dict(linkages_csv,datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update `pub_path` to be: \n",
    "`<name_of_subfolder>_publications.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_pub_path = os.path.join('/Users/mynoa/rc_project/RCPublications/partitions/',rcm_subfolder+'_publications.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_pub_path, 'w') as outfile:\n",
    "    json.dump(linkage_list, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
