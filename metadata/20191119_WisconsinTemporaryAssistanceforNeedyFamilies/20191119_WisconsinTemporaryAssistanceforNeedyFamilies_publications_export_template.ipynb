{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating `publications.json` partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a template notebook for generating metadata on publications - most importantly, the linkage between the publication and dataset (datasets are enumerated in `datasets.json`)\n",
    "\n",
    "Process goes as follows:\n",
    "1. Import CSV with publication-dataset linkages. Your csv should have at the minimum, fields (spelled like the below):\n",
    "    * `dataset` to hold the dataset_ids, and \n",
    "    * `title` for the publication title. \n",
    "\n",
    "Update the csv with these field names to ensure this code will run.  We read in, dedupe and format the title\n",
    "2. Match to `datasets.json` -- alert if given dataset doesn't exist yet\n",
    "3. Generate list of dicts with publication metadata\n",
    "4. Write to a publications.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import CSV containing publication-dataset linkages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `linkages_path` to the location of the csv containg dataset-publication linkages and read in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'WisconsinUnemploymentInsurance_linkages_mynoa.csv'\n",
    "rcm_subfolder = '20191119_WisconsinUnemploymentInsurance'\n",
    "parent_folder = '/Users/mynoa/rc_project/RichContextMetadata/metadata'\n",
    "linkages_path =  os.path.join(parent_folder,rcm_subfolder,file_name)\n",
    "# linkages_path =  os.path.join(os.getcwd(),'SNAP_DATA_DIMENSIONS_SEARCH_DEMO.csv')\n",
    "linkages_csv = pd.read_csv(linkages_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format/clean linkage data - apply `scrub_unicode` to `title` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_unicode (text):\n",
    "    \"\"\"\n",
    "    try to handle the unicode edge cases encountered in source text,\n",
    "    as best as possible\n",
    "    \"\"\"\n",
    "    x = \" \".join(map(lambda s: s.strip(), text.split(\"\\n\"))).strip()\n",
    "\n",
    "    x = x.replace('“', '\"').replace('”', '\"')\n",
    "    x = x.replace(\"‘\", \"'\").replace(\"’\", \"'\").replace(\"`\", \"'\")\n",
    "    x = x.replace(\"`` \", '\"').replace(\"''\", '\"')\n",
    "    x = x.replace('…', '...').replace(\"\\\\u2026\", \"...\")\n",
    "    x = x.replace(\"\\\\u00ae\", \"\").replace(\"\\\\u2122\", \"\")\n",
    "    x = x.replace(\"\\\\u00a0\", \" \").replace(\"\\\\u2022\", \"*\").replace(\"\\\\u00b7\", \"*\")\n",
    "    x = x.replace(\"\\\\u2018\", \"'\").replace(\"\\\\u2019\", \"'\").replace(\"\\\\u201a\", \"'\")\n",
    "    x = x.replace(\"\\\\u201c\", '\"').replace(\"\\\\u201d\", '\"')\n",
    "\n",
    "    x = x.replace(\"\\\\u20ac\", \"€\")\n",
    "    x = x.replace(\"\\\\u2212\", \" - \") # minus sign\n",
    "\n",
    "    x = x.replace(\"\\\\u00e9\", \"é\")\n",
    "    x = x.replace(\"\\\\u017c\", \"ż\").replace(\"\\\\u015b\", \"ś\").replace(\"\\\\u0142\", \"ł\")    \n",
    "    x = x.replace(\"\\\\u0105\", \"ą\").replace(\"\\\\u0119\", \"ę\").replace(\"\\\\u017a\", \"ź\").replace(\"\\\\u00f3\", \"ó\")\n",
    "\n",
    "    x = x.replace(\"\\\\u2014\", \" - \").replace('–', '-').replace('—', ' - ')\n",
    "    x = x.replace(\"\\\\u2013\", \" - \").replace(\"\\\\u00ad\", \" - \")\n",
    "\n",
    "    x = str(unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"utf-8\"))\n",
    "\n",
    "    # some content returns text in bytes rather than as a str ?\n",
    "    try:\n",
    "        assert type(x).__name__ == \"str\"\n",
    "    except AssertionError:\n",
    "        print(\"not a string?\", type(x), x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrub titles of problematic characters, drop nulls and dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkages_csv = linkages_csv.loc[pd.notnull(linkages_csv.dataset)].drop_duplicates()\n",
    "linkages_csv = linkages_csv.loc[pd.notnull(linkages_csv.title)].drop_duplicates()\n",
    "linkages_csv['title'] = linkages_csv['title'].apply(scrub_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>search_term</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dataset-063</td>\n",
       "      <td>10.1177/1091142116629204</td>\n",
       "      <td>Public Finance Review</td>\n",
       "      <td>Wisconsin Unemployment Insurance</td>\n",
       "      <td>EITC Use in Shared Placement Cases</td>\n",
       "      <td>https://doi.org/10.1177/1091142116629204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>dataset-063</td>\n",
       "      <td>10.4324/9781315394503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin Unemployment Insurance</td>\n",
       "      <td>Federalism and the Making of America, 2nd</td>\n",
       "      <td>https://doi.org/10.4324/9781315394503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>dataset-063</td>\n",
       "      <td>10.1177/0192513x14565701</td>\n",
       "      <td>{'id': 'jour.1091259', 'title': 'Journal of Fa...</td>\n",
       "      <td>Wisconsin Unemployment Insurance</td>\n",
       "      <td>Child Support and Subsequent Nonmarital Fertil...</td>\n",
       "      <td>https://doi.org/10.1177/0192513x14565701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dataset-063</td>\n",
       "      <td>10.1016/j.childyouth.2016.10.018</td>\n",
       "      <td>{'id': 'jour.1092724', 'title': 'Children and ...</td>\n",
       "      <td>Wisconsin Unemployment Insurance</td>\n",
       "      <td>Making parents pay: The unintended consequence...</td>\n",
       "      <td>https://doi.org/10.1016/j.childyouth.2016.10.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dataset-063</td>\n",
       "      <td>10.1007/s10940-014-9242-5</td>\n",
       "      <td>{'id': 'jour.1041809', 'title': 'Journal of Qu...</td>\n",
       "      <td>Wisconsin Unemployment Insurance</td>\n",
       "      <td>An Experimental Evaluation of a Comprehensive ...</td>\n",
       "      <td>https://doi.org/10.1007/s10940-014-9242-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset                               doi  \\\n",
       "0  dataset-063          10.1177/1091142116629204   \n",
       "1  dataset-063             10.4324/9781315394503   \n",
       "2  dataset-063          10.1177/0192513x14565701   \n",
       "3  dataset-063  10.1016/j.childyouth.2016.10.018   \n",
       "4  dataset-063         10.1007/s10940-014-9242-5   \n",
       "\n",
       "                                             journal  \\\n",
       "0                              Public Finance Review   \n",
       "1                                                NaN   \n",
       "2  {'id': 'jour.1091259', 'title': 'Journal of Fa...   \n",
       "3  {'id': 'jour.1092724', 'title': 'Children and ...   \n",
       "4  {'id': 'jour.1041809', 'title': 'Journal of Qu...   \n",
       "\n",
       "                        search_term  \\\n",
       "0  Wisconsin Unemployment Insurance   \n",
       "1  Wisconsin Unemployment Insurance   \n",
       "2  Wisconsin Unemployment Insurance   \n",
       "3  Wisconsin Unemployment Insurance   \n",
       "4  Wisconsin Unemployment Insurance   \n",
       "\n",
       "                                               title  \\\n",
       "0                 EITC Use in Shared Placement Cases   \n",
       "1          Federalism and the Making of America, 2nd   \n",
       "2  Child Support and Subsequent Nonmarital Fertil...   \n",
       "3  Making parents pay: The unintended consequence...   \n",
       "4  An Experimental Evaluation of a Comprehensive ...   \n",
       "\n",
       "                                                url  \n",
       "0          https://doi.org/10.1177/1091142116629204  \n",
       "1             https://doi.org/10.4324/9781315394503  \n",
       "2          https://doi.org/10.1177/0192513x14565701  \n",
       "3  https://doi.org/10.1016/j.childyouth.2016.10.018  \n",
       "4         https://doi.org/10.1007/s10940-014-9242-5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkages_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_metadata_fields = ['title']\n",
    "original_metadata_cols = list(set(linkages_csv.columns.values.tolist()) - set(pub_metadata_fields)-set(['dataset']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate list of dicts of metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in `datasets.json`. Update `datasets_path` to your local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = '/Users/mynoa/rc_project/RCDatasets/datasets.json'\n",
    "\n",
    "with open(datasets_path) as json_file:\n",
    "    datasets = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of dictionaries of publication metadata. `format_metadata` iterrates through `linkages_csv` dataframe, splits the `dataset` field (for when multiple datasets are listed); throws an error if the dataset doesn't exist and needs to be added to `datasets.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pub_dict(linkages_dataframe,datasets):\n",
    "    pub_dict_list = []\n",
    "    for i, r in linkages_dataframe.iterrows():\n",
    "        r['title'] = scrub_unicode(r['title'])\n",
    "        ds_id_list = [f for f in [d.strip() for d in r['dataset'].split(\",\")] if f not in [\"\",\" \"]]\n",
    "        for ds in ds_id_list:\n",
    "            check_ds = [b for b in datasets if b['id'] == ds]\n",
    "            if len(check_ds) == 0:\n",
    "                print('dataset {} isnt listed in datasets.json. Please add to file'.format(ds))\n",
    "        required_metadata = r[pub_metadata_fields].to_dict()\n",
    "        required_metadata.update({'datasets':ds_id_list})\n",
    "        pub_dict = required_metadata\n",
    "        if len(original_metadata_cols) > 0:\n",
    "            original_metadata = r[original_metadata_cols].to_dict()\n",
    "            original_metadata.update({'date_added':datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n",
    "            pub_dict.update({'original':original_metadata})\n",
    "        pub_dict_list.append(pub_dict)\n",
    "    return pub_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate publication metadata and export to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_list = create_pub_dict(linkages_csv,datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update `pub_path` to be: \n",
    "`<name_of_subfolder>_publications.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_pub_path = os.path.join('/Users/mynoa/rc_project/RCPublications/partitions/',rcm_subfolder+'_publications.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_pub_path, 'w') as outfile:\n",
    "    json.dump(linkage_list, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
