{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'gen_dataset.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run -i 'gen_dataset.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gen_datasets.ipynb to script\n",
      "[NbConvertApp] Writing 2300 bytes to gen_datasets.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script gen_datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from os import listdir\n",
    "import gen_datasets\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "import metadata_funs\n",
    "import xlrd\n",
    "# from datetime import date\n",
    "import datetime\n",
    "from os.path import isfile, join\n",
    "import ntpath\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_dictionary():\n",
    "    ex_data_path = os.path.join(os.getcwd(),'dataset_metadata/ADRF Dataset Metadata.xlsx')\n",
    "    xls = pd.ExcelFile(ex_data_path)\n",
    "    sheet_to_df_map = pd.read_excel(ex_data_path, sheet_name=None)\n",
    "    uniform_sheets = ['course1-datasets','course2-datasets' ,'kcmo-datasets', 'in_data_2019-datasets'\n",
    "    , 'mo_data_2019-datasets', 'usda-datasets','bundesbank-rc']\n",
    "    lim_excel_df_sheets  = []\n",
    "    for i,v in enumerate(sheet_to_df_map):\n",
    "        if v in uniform_sheets:\n",
    "            lim_excel_df_sheets.append(sheet_to_df_map[v])\n",
    "    return lim_excel_df_sheets      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_dictionary(lim_excel_df_sheets):\n",
    "    common_fields = list(set(lim_excel_df_sheets[6].columns.values) & set(lim_excel_df_sheets[5].columns.values))\n",
    "    new_df_list = []\n",
    "    for i in range(len(lim_excel_df_sheets)):\n",
    "        a = lim_excel_df_sheets[i][common_fields]\n",
    "        new_df_list.append(a)\n",
    "    df = pd.concat(new_df_list).drop_duplicates()\n",
    "    df = df.reset_index()\n",
    "    df['dataset_id'] = [\"dataset-{}\".format(metadata_funs.get_hash(df['title'][_])) for _ in range(len(df.index))]\n",
    "#     df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df.title))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_excel_df_sheets  = read_data_dictionary()\n",
    "dd_df = gen_data_dictionary(lim_excel_df_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd_df.loc[dd_df.title == 'IRI Infoscan data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_dict = dd_df.to_dict('records')\n",
    "# dd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd_dict[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dd_dict:\n",
    "    if isinstance(i['temporal_coverage_end'], datetime.date):\n",
    "        i['temporal_coverage_end'] = str(dateutil.parser.parse(str(i['temporal_coverage_end'])).date())\n",
    "    if isinstance(i['temporal_coverage_start'], datetime.date):\n",
    "        i['temporal_coverage_start'] = str(dateutil.parser.parse(str(i['temporal_coverage_start'])).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dd_dict, open('./datasets.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
